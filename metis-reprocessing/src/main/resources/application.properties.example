#The multiplication of min.parallel.threads and max.parallel.threads.per.datasets is the total amount of threads the application will utilize.
#This is calculated based on the page size and the number of pages per dataset.
min.parallel.datasets=
max.parallel.threads.per.dataset=
start.from.dataset.index=
end.at.dataset.index=
source.mongo.page.size=
#Possible values DEFAULT, REPROCESS_ALL_FAILED, POST_PROCESS. The REPROCESS_ALL_FAILED will process only the
#failed records for a dataset even if it's not previously completely processed.
#POST_PROCESS mode is to be used after everything is final and the last step needs to be executed.
#Don't use this mode unless you know what you are doing.
mode=DEFAULT
#A list of dataset ids to process instead of all the datasets
dataset.ids.to.process=
#Set to true to do a simple read and then write reindex, without altering the record
identity.process=
#Set to true if we want to clear the database before we start a new process
clear.databases.before.process=
invalidate.plugin.types=
reprocess.based.on.plugin.type=

#Truststore
truststore.path=
truststore.password=

#Mongo Metis Core
mongo.metis.core.hosts=
mongo.metis.core.port=
mongo.metis.core.authentication.db=
mongo.metis.core.username=
mongo.metis.core.password=
mongo.metis.core.enableSSL=false
mongo.metis.core.db=

#Mongo Source
mongo.source.hosts=
mongo.source.port=
mongo.source.authentication.db=
mongo.source.username=
mongo.source.password=
mongo.source.enableSSL=false
mongo.source.db=

#Mongo Destination
mongo.destination.hosts=
mongo.destination.port=
mongo.destination.authentication.db=
mongo.destination.username=
mongo.destination.password=
mongo.destination.enableSSL=false
mongo.destination.db=

#Solr/Zookeeper Destination
solr.destination.hosts=
zookeeper.destination.hosts=
zookeeper.destination.port=
zookeeper.destination.chroot=
zookeeper.destination.defaultCollection=

#EXTRA CONFIGURATION
